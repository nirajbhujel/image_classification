{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8167b787-30bd-4479-bc97-e536126b20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import math\n",
    "import shutil\n",
    "import hydra\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "\n",
    "from datasets.dataset import LaserImageDataset, get_transforms\n",
    "from models.network import Network\n",
    "\n",
    "from utils.metrics import MetricLogger\n",
    "from utils.misc import create_new_dir, copy_src\n",
    "from utils.utils import set_random_seed, model_parameters\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45892801-01f6-43f0-bc94-51cc64cdca61",
   "metadata": {},
   "source": [
    "## Specify directory to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9672e111-2a51-4857-adf1-2cfdb8cad2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating exp : session001/exp1_PointCNN_Grating_A6_Grating_SON1_LASEROPTIK_LASEROPTIK_SON1_seed3061994_lr0.0003_e500_b64\n",
      "log_dir = ../logs/session001/exp1_PointCNN_Grating_A6_Grating_SON1_LASEROPTIK_LASEROPTIK_SON1_seed3061994_lr0.0003_e500_b64\n"
     ]
    }
   ],
   "source": [
    "ckpt_name = 'best_acc'\n",
    "exp_dir = 'session001/exp1_PointCNN_Grating_A6_Grating_SON1_LASEROPTIK_LASEROPTIK_SON1_seed3061994_lr0.0003_e500_b64'\n",
    "\n",
    "print(\"Evaluating exp :\", exp_dir)\n",
    "\n",
    "log_dir = \"../logs/\" + exp_dir\n",
    "ckpt_dir = log_dir + \"/checkpoints\"\n",
    "print(f\"log_dir = {log_dir}\")\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    raise Exception(f\"{log_dir} doesn't exists\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef51de7-a109-4f03-b9f2-8526f572683f",
   "metadata": {},
   "source": [
    "## Load cfg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25a572a8-7e2d-454b-9857-43fd26ef106d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeds:\n",
      "- 3061994\n",
      "task: classification\n",
      "num_classes: 2\n",
      "net:\n",
      "  type: PointCNN\n",
      "  hidden_dim: 512\n",
      "  out_dim: 512\n",
      "loss:\n",
      "  bce_loss:\n",
      "    weight: 1.0\n",
      "    learn_weight: false\n",
      "  mse_loss:\n",
      "    weight: 0.0\n",
      "    learn_weight: false\n",
      "optim:\n",
      "  lr: 0.0003\n",
      "  lr_min: 1.0e-06\n",
      "  lr_scheduler: reduceonplateau\n",
      "  warmup_epochs: 0\n",
      "  lr_patience: 10\n",
      "  lr_reduce_factor: 0.9\n",
      "  lr_adjust: false\n",
      "  lr_adjust_rule: ''\n",
      "  weight_decay: 0\n",
      "  weight_decay_end: 1.0\n",
      "  clip_grad: 1.0\n",
      "data:\n",
      "  img_height: 480\n",
      "  img_width: 480\n",
      "  n_channels: 1\n",
      "  aug_photo: 0.0\n",
      "  aug_geome: 0.5\n",
      "  data_dir: ../data/near_field\n",
      "  datasets:\n",
      "  - Grating_A6\n",
      "  - Grating_SON1\n",
      "  - LASEROPTIK\n",
      "  - LASEROPTIK_SON1\n",
      "  val_split: 0.4\n",
      "  prefetch: 1\n",
      "train:\n",
      "  session: 1\n",
      "  epochs: 500\n",
      "  batch_size: 64\n",
      "  num_workers: 1\n",
      "  gpu: 0\n",
      "  ddp: false\n",
      "  dist_run: false\n",
      "  resume_training: false\n",
      "  single_batch: false\n",
      "  debug: false\n",
      "  early_stop_metric: val/acc\n",
      "  early_stop_patience: 20\n",
      "  eval_interval: 10\n",
      "  log_interval: 100\n",
      "  n_images: 20\n",
      "  eval_metric: val/acc\n",
      "  train_skip_frames: 1\n",
      "  test_skip_frames: 1\n",
      "  reset_head_steps: null\n",
      "  network_in: null\n",
      "exp:\n",
      "  name: exp1\n",
      "  log_dir: ../logs/session001/exp1_PointCNN_Grating_A6_Grating_SON1_LASEROPTIK_LASEROPTIK_SON1_seed3061994_lr0.0003_e500_b64\n",
      "  ckpt_dir: ../logs/session001/exp1_PointCNN_Grating_A6_Grating_SON1_LASEROPTIK_LASEROPTIK_SON1_seed3061994_lr0.0003_e500_b64/checkpoints\n",
      "  summary_dir: ../logs/session001/exp1_PointCNN_Grating_A6_Grating_SON1_LASEROPTIK_LASEROPTIK_SON1_seed3061994_lr0.0003_e500_b64/summary\n",
      "  seed: 3061994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "cfg = OmegaConf.load(log_dir + '/cfg.yaml')\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a405f-928e-4db6-94e7-bb24f7583d86",
   "metadata": {},
   "source": [
    "## Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b87d8b6-7990-4832-a71e-1d5bdf67d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint from  ../logs/session001/exp1_PointCNN_Grating_A6_Grating_SON1_LASEROPTIK_LASEROPTIK_SON1_seed3061994_lr0.0003_e500_b64/checkpoints/best_acc\n",
      "Model loaded sucessfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Checkpoint from \", ckpt_dir + '/' + ckpt_name)\n",
    "network = Network(cfg)\n",
    "# print(network)\n",
    "\n",
    "states = torch.load(ckpt_dir + '/' + ckpt_name + '.pth')\n",
    "if ckpt_name == 'model_states':\n",
    "    states = states['model_state']\n",
    "\n",
    "network.load_state_dict(states, strict=True)\n",
    "network = network.eval()\n",
    "print(\"Model loaded sucessfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce655bdf-c977-4e18-ad83-c6ee73484be0",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9feb4b5f-8372-4fab-a1f7-bea243a064d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting THALES_SESO_A labels into train and validaton set\n",
      "Class 0: 6503/8100 val samples\n",
      "Class 1: 1597/8100 val samples\n",
      "Evaluation samples: 8100, Bathces: 32\n"
     ]
    }
   ],
   "source": [
    "from datasets.dataset import LaserImageDataset\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "cfg.data.datasets = ['THALES_SESO_A']\n",
    "cfg.data.prefetch = False\n",
    "cfg.data.val_split = 1\n",
    "eval_dataset = LaserImageDataset(cfg.data,\n",
    "                                phase='val',\n",
    "                                img_transform=get_transforms(cfg.data, \"val\"),\n",
    "                                num_classes=cfg.num_classes,\n",
    "                                balanced_class=False,\n",
    "                                shuffle_labels=False,\n",
    "                                )\n",
    "\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=256, shuffle=False, num_workers=1)\n",
    "\n",
    "print(f\"Evaluation samples: {len(eval_dataset)}, Bathces: {len(eval_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b184b-ccc5-457b-b055-10ec0570713e",
   "metadata": {},
   "source": [
    "## Prepare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "178ce34d-c878-4a77-b7e6-3aa3d75fec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(cfg.exp.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "network = network.to(device)\n",
    "\n",
    "date_time = datetime.now().strftime(\"%d%m%Y\")\n",
    "# date_time = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "\n",
    "result_dir = log_dir + f\"/evaluations/{date_time}_{'_'.join(cfg.data.datasets)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10569c06-7e3b-4e17-9de4-c83fd7cfb38a",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1803093f-57c8-4ec6-97f7-cb3474a60037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 93/127 [00:25<00:09,  3.63it/s, 0.937500]\n",
      "100%|██████████| 32/32 [00:25<00:00,  1.41it/s, 1.000000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric           tp       fp       tn       fn       accuracy    precision\n",
      "---------------  -------  -------  -------  -------  ----------  -----------\n",
      "binary_accuracy  7973.00  127.00   7973.00  127.00   0.98        0.98\n",
      "-------          -------  -------  -------  -------  -------     -------\n"
     ]
    }
   ],
   "source": [
    "from utils.metrics import MetricLogger\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#eval_metrics = BinaryAccuracy(multidim_average='global').to(device)\n",
    "eval_metrics = MetricLogger()\n",
    "\n",
    "eval_results = [] \n",
    "\n",
    "pbar = tqdm(total=len(eval_dataloader), position=0)\n",
    "with torch.no_grad():\n",
    "    for iter, batch in enumerate(eval_dataloader):\n",
    "        pbar.update(1)\n",
    "\n",
    "        imgs, labels, img_files = batch\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = network(imgs)\n",
    "        preds = F.softmax(preds, dim=-1)\n",
    "\n",
    "        acc = eval_metrics.update(preds, labels)\n",
    "\n",
    "        for f, l, p in zip(img_files, labels, preds):\n",
    "            eval_results.append(dict(img=f, label=l.argmax().item(), pred=p.argmax().item(), prob=p.max().item()))\n",
    "            \n",
    "        pbar.set_postfix_str(f\"{acc:03f}\")\n",
    "        # break\n",
    "\n",
    "eval_metrics.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc235ee-945a-4762-83ca-0a09509ac5ba",
   "metadata": {},
   "source": [
    "## Save eval results to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0fced155-eb97-4a3c-8b28-6223d3b835dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from datasets.preprocess import generate_html\n",
    "from utils.misc import save_file\n",
    "\n",
    "data_dir = \"/home/ubuntu/Projects/clf-laser-damage-prediction/data/near_field/images/\"\n",
    "\n",
    "html_data = generate_html(eval_results, data_dir, title='Eval Results')\n",
    "save_file('../logs/eval_results.html', html_data)\n",
    "\n",
    "# with open(f\"../logs/eval_results.html\", 'w+') as f:\n",
    "#     f.write(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "321ab2d4-f177-45fa-bdfe-8092db5ae214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', [10, 20]), ('b', 5), ('c', 20)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted({'a': [10, 20], 'c': 20, 'b':5}.items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laser-damage",
   "language": "python",
   "name": "laser-damage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
